{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nfrom sklearn.model_selection import train_test_split,GridSearchCV, cross_val_score\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport warnings  \nwarnings.filterwarnings('ignore')\n\nfrom sklearn.metrics import f1_score\n\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier\n\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import Perceptron\nfrom sklearn.linear_model import SGDClassifier\nfrom xgboost import XGBClassifier,XGBRFClassifier\nfrom sklearn.model_selection import cross_val_score\n\nfrom collections import Counter\n\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier, VotingClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold, learning_curve\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train=pd.read_csv('/kaggle/input/data-storm-20/Hotel-A-train.csv')\nvali=pd.read_csv('/kaggle/input/data-storm-20/Hotel-A-validation.csv')\n\ntest=pd.read_csv('/kaggle/input/data-storm-20/Hotel-A-test.csv')\ntest_set=test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vali","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.dtypes=='int64'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_I=[]\n\nfor i in train['Income']:\n    \n    if (i=='<25K'):\n        new_I.append(1)\n    elif (i=='25K --50K'):\n        new_I.append(2)\n    elif (i=='50K -- 100K'):\n        new_I.append(3)\n    else:\n        new_I.append(4)\nnew_I=pd.DataFrame(new_I)\ntrain.insert(6,'New_Income',new_I)\n    \nnew_I=[]\nfor i in vali['Income']:\n    \n    if (i=='<25K'):\n        new_I.append(1)\n    elif (i=='25K --50K'):\n        new_I.append(2)\n    elif (i=='50K -- 100K'):\n        new_I.append(3)\n    else:\n        new_I.append(4)\nnew_I=pd.DataFrame(new_I)\nvali.insert(6,'New_Income',new_I)\n\nnew_I=[]\nfor i in test['Income']:\n    \n    if (i=='<25K'):\n        new_I.append(1)\n    elif (i=='25K --50K'):\n        new_I.append(2)\n    elif (i=='50K -- 100K'):\n        new_I.append(3)\n    else:\n        new_I.append(4)\nnew_I=pd.DataFrame(new_I)\ntest.insert(6,'New_Income',new_I)\n\ntrain=train.drop( 'Income',axis=1)\nvali=vali.drop( 'Income',axis=1)\ntest=test.drop('Income', axis=1)\n\n\nnew_E=[]\n\nfor i in train['Educational_Level']:\n    \n    if (i=='Mid-School'):\n        new_E.append(1)\n    elif (i=='High-School'):\n        new_E.append(2)\n    elif (i=='College'):\n        new_E.append(3)\n    else:\n        new_E.append(4)\n\n    \nnew_E=pd.DataFrame(new_E)\ntrain.insert(5,'New_Education',new_E)\n\n\n\nnew_E=[]\n\nfor i in vali['Educational_Level']:\n    \n    if (i=='Mid-School'):\n        new_E.append(1)\n    elif (i=='High-School'):\n        new_E.append(2)\n    elif (i=='College'):\n        new_E.append(3)\n    else:\n        new_E.append(4)\n\n    \nnew_E=pd.DataFrame(new_E)\nvali.insert(5,'New_Education',new_E)\n\n\nnew_E=[]\n\nfor i in test['Educational_Level']:\n    \n    if (i=='Mid-School'):\n        new_E.append(1)\n    elif (i=='High-School'):\n        new_E.append(2)\n    elif (i=='College'):\n        new_E.append(3)\n    else:\n        new_E.append(4)\n\n    \nnew_E=pd.DataFrame(new_E)\ntest.insert(5,'New_Education',new_E)\n\ntrain=train.drop( 'Educational_Level',axis=1)\nvali=vali.drop( 'Educational_Level',axis=1)\ntest=test.drop('Educational_Level',axis=1)\n\n\nReservation=[]\n\nfor i in train['Reservation_Status']:\n    \n    if (i=='Check-In'):\n        Reservation.append(1)\n    elif (i=='Canceled'):\n        Reservation.append(2)\n    elif (i=='No-Show'):\n        Reservation.append(3)\n\n    \nReservation=pd.DataFrame(Reservation)\ntrain.insert(18,'New_Reservation_Status',Reservation)\n\n\n\nReservation=[]\n\nfor i in vali['Reservation_Status']:\n    \n    if (i=='Check-In'):\n        Reservation.append(1)\n    elif (i=='Canceled'):\n        Reservation.append(2)\n    elif (i=='No-Show'):\n        Reservation.append(3)\n  \n\n    \nReservation=pd.DataFrame(Reservation)\nvali.insert(18,'New_Reservation_Status',Reservation)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train=train.drop( 'Reservation_Status',axis=1)\nvali=vali.drop( 'Reservation_Status',axis=1)\n\n\ntarget = 'New_Reservation_Status'\nID = 'Reservation-id'\n\ny=train[target]\nvali_target=vali[target]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train=train.drop([target,ID,'Booking_date','Expected_checkin', 'Expected_checkout'],axis=1)\nvali=vali.drop([target,ID,'Booking_date','Expected_checkin', 'Expected_checkout'],axis=1)\ntest=test.drop([ID,'Booking_date','Expected_checkin', 'Expected_checkout'],axis=1)\n\n\nfamily=train[['Adults','Children','Babies']].sum(axis=1)\ntrain.insert(6,'Family',family)\n\nfamily=vali[['Adults','Children','Babies']].sum(axis=1)\nvali.insert(6,'Family',family)\n\nfamily=test[['Adults','Children','Babies']].sum(axis=1)\ntest.insert(6,'Family',family)\n\ntrain=train.drop(['Adults','Children','Babies'],axis=1)\nvali=vali.drop(['Adults','Children','Babies'],axis=1)\ntest=test.drop(['Adults','Children','Babies'],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"numerical_column=[col for col in train.columns if train[col].dtype in ['int64','float64']]\n\n# find the categorical column in the data\ncategorical_column=list(set(train.columns)-set(numerical_column))\n\nprint(\"Numerical columns\",numerical_column)\nprint('Categorical columns',categorical_column)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"encoding_instance = OneHotEncoder(handle_unknown='ignore')\ntrain_OneHot = pd.DataFrame(encoding_instance.fit_transform(train[categorical_column]).toarray())\n\nencoding_instance = OneHotEncoder(handle_unknown='ignore')\nvali_OneHot = pd.DataFrame(encoding_instance.fit_transform(vali[categorical_column]).toarray())\n\nencoding_instance = OneHotEncoder(handle_unknown='ignore')\ntest_OneHot = pd.DataFrame(encoding_instance.fit_transform(test[categorical_column]).toarray())\n\n\ntrain_data = pd.concat([train,train_OneHot],axis=1)\nvali_data = pd.concat([vali,vali_OneHot],axis=1)\ntest_data=pd.concat([test,test_OneHot], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = train_data.drop( categorical_column,axis=1)\nscaler = StandardScaler().fit(X)\nX = pd.DataFrame(scaler.transform(X))\n\n\nvali = vali_data.drop(categorical_column,axis=1)\nscaler = StandardScaler().fit(vali)\nvali = pd.DataFrame(scaler.transform(vali))\n\n\ntest=test_data.drop(categorical_column,axis=1)\nscaler=StandardScaler().fit(test)\ntest=pd.DataFrame(scaler.transform(test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def CreateBalancedSampleWeights(y_train, largest_class_weight_coef):\n    classes = y_train.unique()\n    classes.sort()\n    class_samples = np.bincount(y_train)\n    total_samples = class_samples.sum()\n    n_classes = len(class_samples)\n    weights = total_samples / (n_classes * class_samples * 1.0)\n    class_weight_dict = {key : value for (key, value) in zip(classes, weights)}\n    class_weight_dict[classes[1]] = class_weight_dict[classes[1]] * largest_class_weight_coef\n    sample_weights = [class_weight_dict[y] for y in y_train]\n\n    return sample_weights\n\n\n\nlargest_class_weight_coef = max(y.value_counts().values)/y.shape[0]\n #pass y_train as numpy array\nweight = CreateBalancedSampleWeights(y, largest_class_weight_coef)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.utils.class_weight import compute_sample_weight\nfrom xgboost import XGBRFClassifier\nw=compute_sample_weight(class_weight='balanced', y=y)\n#xg=XGBClassifier(n_estimators=200,learning_rate=0.05, max_depth=10)\n\n#xg = XGBClassifier(objective=\"multi:softprob\", n_estimators=600,learning_rate=0.01, max_depth=10,random_state=42)\n\nxg = XGBRFClassifier(n_estimators=1000,learning_rate=0.01 ,max_depth=10,random_state=42)\nxg.fit(X, y,sample_weight = w)\npred = xg.predict(vali)    \nprint ('-------------------------------------')\nprint('')\nprint(confusion_matrix(vali_target,pred))\n\na=f1_score(vali_target,pred, average='macro')\n\nprint(a)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sss","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ntest_prediction=xg.predict(test)\noutput = pd.DataFrame({'Reservation-id': test_set[ID],\n                  'Reservation_Status': test_prediction})\noutput.to_csv('my_submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}